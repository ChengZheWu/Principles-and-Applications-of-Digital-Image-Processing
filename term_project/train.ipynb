{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e23598a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/andy/anaconda3/envs/tf1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/data/andy/anaconda3/envs/tf1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/data/andy/anaconda3/envs/tf1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/data/andy/anaconda3/envs/tf1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/data/andy/anaconda3/envs/tf1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/data/andy/anaconda3/envs/tf1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/data/andy/kaggle_facemask/keras-yolo3\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# !git clone https://github.com/qqwweee/keras-yolo3 # 如果之前已經下載過就可以註解掉\n",
    "if os.getcwd()[-11:] != 'keras-yolo3':\n",
    "    %cd keras-yolo3\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data\n",
    "from train import get_classes, get_anchors, create_model, create_tiny_model, data_generator, data_generator_wrapper\n",
    "\n",
    "datafolder = \"/data/NFS/andy/yolo/kaggle_facemask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b7505c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exist\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"model_data/yolo.h5\"):\n",
    "    # 下載 yolov3 的網路權重，並且把權重轉換為 keras 能夠讀取的格式\n",
    "    print(\"Download YOLOv3 weights from YOLO website...\")\n",
    "    os.system(\"wget https://pjreddie.com/media/files/yolov3.weights\")\n",
    "    print(\"Convert the Darknet YOLO model to a Keras model...\")\n",
    "    os.system(\"python3 convert.py yolov3.cfg yolov3.weights model_data/yolo.h5\")\n",
    "else:\n",
    "    print(\"Model exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ffaddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = glob(datafolder + \"images/*.png\")\n",
    "imgs_path.sort()\n",
    "num = int(len(imgs_path)*0.1)\n",
    "\n",
    "f = open(datafolder + \"train.txt\", \"w\")\n",
    "for i in range(num*9):\n",
    "    name = imgs_path[i][43:-4]\n",
    "    f.write(name + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open(datafolder + \"val.txt\", \"w\")\n",
    "for i in range(num*9, len(imgs_path)):\n",
    "    name = imgs_path[i][43:-4]\n",
    "    f.write(name + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91fce6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save annotation at train.txt\n",
      "save annotation at val.txt\n"
     ]
    }
   ],
   "source": [
    "sets=['train', 'val']\n",
    "\n",
    "# Facemask 的資料類別\n",
    "classes = [\"with_mask\", \"without_mask\", \"mask_weared_incorrect\"]\n",
    "\n",
    "# 把 annotation 轉換訓練時需要的資料形態\n",
    "def convert_annotation(image_id, list_file):\n",
    "    in_file = open(datafolder + 'annotations/%s.xml'%(image_id))\n",
    "    tree=ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in classes or int(difficult)==1:\n",
    "            continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n",
    "        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n",
    "\n",
    "for image_set in sets:\n",
    "    image_ids = open(datafolder + '%s.txt'%(image_set)).read().strip().split()\n",
    "    annotation_path = '%s.txt'%(image_set)\n",
    "    list_file = open(annotation_path, 'w')\n",
    "    print(\"save annotation at %s\" % annotation_path)\n",
    "    for image_id in image_ids:\n",
    "        list_file.write(datafolder + 'images/%s.png'%(image_id))\n",
    "        convert_annotation(image_id, list_file)\n",
    "        list_file.write('\\n')\n",
    "    list_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70b6059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"model_data/yolo_weights.h5\"):\n",
    "    print(\"Converting pretrained YOLOv3 weights for training\")\n",
    "    os.system(\"python3 convert.py -w yolov3.cfg yolov3.weights model_data/yolo_weights.h5\") \n",
    "else:\n",
    "    print(\"Pretrained weights exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc16432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use yolo\n",
      "Create YOLOv3 model with 9 anchors and 3 classes.\n",
      "Load weights model_data/yolo_weights.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "Train on 689 samples, val on 76 samples, with batch size 32.\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - 65s 3s/step - loss: 5751.3512 - val_loss: 1579.0419\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 835.8329 - val_loss: 446.7018\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 361.6996 - val_loss: 280.2626\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 40s 2s/step - loss: 252.0886 - val_loss: 209.9141\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 200.5649 - val_loss: 177.6026\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 172.0745 - val_loss: 150.7939\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 148.1451 - val_loss: 135.0977\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 130.7593 - val_loss: 125.4146\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 119.3764 - val_loss: 105.5558\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 110.9722 - val_loss: 105.5382\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 101.3202 - val_loss: 92.7926\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 96.8435 - val_loss: 94.9993\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 92.0536 - val_loss: 87.8237\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 85.6832 - val_loss: 83.2958\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 83.3794 - val_loss: 73.4687\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 79.4643 - val_loss: 74.9632\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 75.9288 - val_loss: 75.7893\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 75.4855 - val_loss: 71.0252\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 72.9515 - val_loss: 69.9118\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 70.1318 - val_loss: 66.0446\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 69.3707 - val_loss: 67.4369\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 67.2796 - val_loss: 65.4828\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 68.4722 - val_loss: 63.7367\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 66.8457 - val_loss: 61.4862\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 61.1535 - val_loss: 60.0609\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 61.8396 - val_loss: 62.9701\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 63.2759 - val_loss: 60.7548\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 61.3863 - val_loss: 57.4881\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 60.3592 - val_loss: 65.2293\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 59.0071 - val_loss: 55.1477\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 60.1054 - val_loss: 59.9059\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 59.4158 - val_loss: 57.7130\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 58.2313 - val_loss: 58.1655\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 56.5691 - val_loss: 55.3135\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 58.2619 - val_loss: 55.8140\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 56.6354 - val_loss: 52.0637\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 56.3052 - val_loss: 63.5637\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 55.9282 - val_loss: 52.5521\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 56.2641 - val_loss: 51.5212\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 55.2190 - val_loss: 56.6284\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 55.2982 - val_loss: 49.7550\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 54.1515 - val_loss: 59.1483\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 54.8465 - val_loss: 53.2314\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 54.5196 - val_loss: 51.4042\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 53.6333 - val_loss: 54.9479\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 53.5563 - val_loss: 51.0668\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 52.2034 - val_loss: 56.7276\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 52.0645 - val_loss: 55.7037\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 53.3631 - val_loss: 51.0804\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 52.4481 - val_loss: 50.8007\n",
      "Unfreeze all of the layers.\n",
      "Train on 689 samples, val on 76 samples, with batch size 4.\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 90s 522ms/step - loss: 34.6513 - val_loss: 31.9703\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 74s 430ms/step - loss: 29.7152 - val_loss: 29.7375\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 74s 429ms/step - loss: 28.2561 - val_loss: 29.3074\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 74s 428ms/step - loss: 27.5667 - val_loss: 29.5363\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 74s 429ms/step - loss: 26.7615 - val_loss: 28.2618\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 74s 428ms/step - loss: 26.4160 - val_loss: 27.2090\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 74s 431ms/step - loss: 26.6778 - val_loss: 27.3236\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 74s 431ms/step - loss: 26.2474 - val_loss: 27.1045\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 74s 431ms/step - loss: 25.9640 - val_loss: 27.8477\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 74s 431ms/step - loss: 25.0627 - val_loss: 26.0890\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 75s 433ms/step - loss: 24.9648 - val_loss: 25.8608\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 75s 435ms/step - loss: 25.0545 - val_loss: 26.4056\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 74s 432ms/step - loss: 24.2006 - val_loss: 26.7068\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 74s 433ms/step - loss: 24.6963 - val_loss: 25.3575\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 74s 431ms/step - loss: 24.4366 - val_loss: 24.6183\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 75s 433ms/step - loss: 24.3517 - val_loss: 25.0990\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 75s 434ms/step - loss: 24.1197 - val_loss: 26.4345\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 74s 432ms/step - loss: 23.1976 - val_loss: 25.3869\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 74s 430ms/step - loss: 23.4354 - val_loss: 25.5229\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 74s 431ms/step - loss: 22.4004 - val_loss: 24.7042\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 74s 430ms/step - loss: 22.5247 - val_loss: 24.1810\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 75s 433ms/step - loss: 22.4643 - val_loss: 26.0472\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 75s 434ms/step - loss: 22.3160 - val_loss: 26.4310\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 75s 434ms/step - loss: 22.4047 - val_loss: 25.6256\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 74s 432ms/step - loss: 22.7699 - val_loss: 24.4710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "172/172 [==============================] - 74s 433ms/step - loss: 22.0765 - val_loss: 24.3251\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 75s 434ms/step - loss: 21.8788 - val_loss: 24.5969\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 75s 434ms/step - loss: 22.3459 - val_loss: 24.3358\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 74s 431ms/step - loss: 22.6564 - val_loss: 25.5053\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 74s 431ms/step - loss: 22.1077 - val_loss: 23.1706\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 74s 433ms/step - loss: 22.2470 - val_loss: 25.0334\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 74s 428ms/step - loss: 22.2945 - val_loss: 25.0338\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 74s 429ms/step - loss: 21.5317 - val_loss: 24.3523\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 74s 429ms/step - loss: 22.3859 - val_loss: 25.7490\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 75s 433ms/step - loss: 22.4383 - val_loss: 25.5164\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 75s 435ms/step - loss: 22.7578 - val_loss: 26.3517\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 75s 438ms/step - loss: 22.4324 - val_loss: 23.3639\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 115s 669ms/step - loss: 22.5223 - val_loss: 25.6047\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 125s 725ms/step - loss: 22.6624 - val_loss: 24.8451\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 121s 701ms/step - loss: 22.1873 - val_loss: 25.4915\n",
      "Epoch 00090: early stopping\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "annotation_path = 'train.txt' # 轉換好格式的標註檔案\n",
    "log_dir = 'logs/000/' # 訓練好的模型儲存的路徑\n",
    "classes_path = 'model_data/mask_classes.txt'\n",
    "anchors_path = 'model_data/yolo_anchors.txt'\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "\n",
    "input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "is_tiny_version = len(anchors)==6 # default setting\n",
    "if is_tiny_version:\n",
    "    print(\"use tiny yolo\")\n",
    "    model = create_tiny_model(input_shape, anchors, num_classes, freeze_body=2, \n",
    "                              weights_path='model_data/tiny_yolo_weights.h5')\n",
    "else:\n",
    "    print(\"use yolo\")\n",
    "    model = create_model(input_shape, anchors, num_classes, freeze_body=2, \n",
    "                         weights_path='model_data/yolo_weights.h5')\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "# 分為 training 以及 validation\n",
    "val_split = 0.1\n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "np.random.seed(10101)\n",
    "np.random.shuffle(lines)\n",
    "np.random.seed(None)\n",
    "num_val = int(len(lines)*val_split)\n",
    "num_train = len(lines) - num_val\n",
    "\n",
    "# Train with frozen layers first, to get a stable loss.\n",
    "# Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "# 一開始先 freeze YOLO 除了 output layer 以外的 darknet53 backbone 來 train\n",
    "if True:\n",
    "    # use custom yolo_loss Lambda layer.\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "    batch_size = 32\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    # 模型利用 generator 產生的資料做訓練，強烈建議大家去閱讀及理解 data_generator_wrapper 在 train.py 中的實現\n",
    "    history1 = model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=50,\n",
    "            initial_epoch=0,\n",
    "            callbacks=[logging, checkpoint])\n",
    "    model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "# Unfreeze and continue training, to fine-tune.\n",
    "# Train longer if the result is not good.\n",
    "if True:\n",
    "    # 把所有 layer 都改為 trainable\n",
    "    for i in range(len(model.layers)):\n",
    "        model.layers[i].trainable = True\n",
    "    # recompile to apply the change\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "    print('Unfreeze all of the layers.')\n",
    "\n",
    "    batch_size = 4 # note that more GPU memory is required after unfreezing the body\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    history2 = model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=100,\n",
    "        initial_epoch=50,\n",
    "        callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "    model.save_weights(log_dir + 'trained_weights_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd2e2778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history1.history['loss'] + history2.history['loss'])\n",
    "plt.plot(history1.history['val_loss'] + history2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.savefig(log_dir + \"loss.tiff\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
